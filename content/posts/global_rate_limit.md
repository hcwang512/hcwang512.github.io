---
title: "Global rate limit"
date: 2021-10-26T23:43:26+08:00
draft: false
---

rate limit 对于线上服务的稳定性相当重要。单机版的 rate limit 有很多的算法，不具体展开。微服务一般需要分布式的 rate limit. 
设计全局 rate limit 有3个思路。

### 平均分摊到单机
将 limit 平均分配到单机，默认每一个实例会承担相同的流量。这种方法需要事先确定实例数量，并且可能会有较大的误差。

### sticky session
通过 load balance 策略，比如一致性哈希，总是将相同场景的请求转发到同一个(或一批)实例上。这种方法巧妙地将全局问题转化为单机问题。优点是实现简单，缺点也很致命，它的容错和伸缩性都比较差。一般不会用于关键的场景。

### 中心存储
通过 redis/cassadra 将计数信息中心化存储。这种方式可能会在请求量大的时候会有性能问题。
